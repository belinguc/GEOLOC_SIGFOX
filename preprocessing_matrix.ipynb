{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook that preprocess the data\n",
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return df\n",
    "\n",
    "def apply_method(method, df, means, min_rssi, list_of_bs):\n",
    "    if method == 'lat_lng_dummies':\n",
    "        df_feat = lat_lng_dummies(df, list_of_bs, means, min_rssi)\n",
    "    else:\n",
    "        if method == 'rssi':\n",
    "            df_feat = rssis(df, list_of_bs)\n",
    "        elif method == 'rssis_filtered':\n",
    "            df_feat = rssis_filtered(df, list_of_bs)\n",
    "        else:\n",
    "            df_feat = df\n",
    "            print('lol')\n",
    "\n",
    "    return df_feat\n",
    "\n",
    "\n",
    "def get_means(df):\n",
    "    return df[['bs_lat', 'bs_lng']].mean()\n",
    "\n",
    "\n",
    "def compute_total_mean(train, val, test):\n",
    "    train_size = len(train)\n",
    "    val_size = len(val)\n",
    "    test_size = len(test)\n",
    "\n",
    "    means_train = get_means(train)\n",
    "    means_val = get_means(val)\n",
    "    means_test = get_means(test)\n",
    "\n",
    "    total = (means_train * train_size + means_val * val_size + means_test * test_size) / (\n",
    "        train_size + val_size + test_size)\n",
    "    return total\n",
    "\n",
    "def get_min(df):\n",
    "    return df['rssi'].min()\n",
    "\n",
    "\n",
    "def compute_total_min(train, val, test):\n",
    "    total = min([get_min(train), get_min(val), get_min(test)])\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    " # METHOD 3\n",
    "def rssis_filtered_old(df, list_of_bs, filter_threshold):\n",
    "    df = rssi_filter(df, filter_threshold)\n",
    "    df_feat = rssis(df, list_of_bs)\n",
    "    return df_feat\n",
    "\n",
    "\n",
    "def rssi_filter(df, filter_threshold=-140):\n",
    "    \n",
    "    print(df.head())\n",
    "    df_feat = df[df.rssi >= filter_threshold]\n",
    "    print(df_feat.head())\n",
    "    return df_feat\n",
    "\n",
    "\n",
    "def save_csv(df, name):\n",
    "    df.to_csv(name, sep=';', index=False)\n",
    "\n",
    "\n",
    "def ground_truth_const(df_mess, pos):\n",
    "    df_mess_pos = df_mess.copy()\n",
    "    df_mess_pos[['lat', 'lng']] = pos\n",
    "\n",
    "    ground_truth_lat = df_mess_pos.groupby(['objid']).mean()['lat']\n",
    "    ground_truth_lng = df_mess_pos.groupby(['objid']).mean()['lng']\n",
    "\n",
    "    frames = [ground_truth_lat, ground_truth_lng]\n",
    "    ground_truth = pd.concat(frames, axis=1)\n",
    "\n",
    "    return ground_truth\n",
    "\n",
    "# METHOD 1\n",
    "def lat_lng_dummies(df, list_of_bs, means, min_rssi):\n",
    "    list_lats = [str(bs) + '_lat' for bs in list_of_bs]\n",
    "    list_lngs = [str(bs) + '_lng' for bs in list_of_bs]\n",
    "    list_columns = list_lats + list_lngs + ['did']\n",
    "\n",
    "    min_rssi = min_rssi\n",
    "    mean_lats = means['bs_lat']\n",
    "    mean_lngs = means['bs_lng']\n",
    "\n",
    "    df_mess_bs_group = df.groupby(['objid'], as_index=False)  # group data by message (objid)\n",
    "    messages = np.unique(df['objid'])\n",
    "    nb_mess = len(messages)\n",
    "\n",
    "    df_feat = pd.DataFrame(index=np.arange(nb_mess), columns=list_columns)\n",
    "\n",
    "    df_feat.loc[:, :len(list_of_bs)] = mean_lats\n",
    "    df_feat.loc[:, len(list_of_bs):2 * len(list_of_bs)] = mean_lngs\n",
    "    idx = 0\n",
    "\n",
    "    for key, elmt in df_mess_bs_group:\n",
    "        lats = df_mess_bs_group.get_group(key)['bs_lat'].values\n",
    "        lngs = df_mess_bs_group.get_group(key)['bs_lng'].values\n",
    "        df_feat.loc[idx, 'did'] = df_mess_bs_group.get_group(key)['did'].values[0]\n",
    "        for r, bsid in enumerate(df_mess_bs_group.get_group(key)['bsid'], 0):\n",
    "            lat = str(bsid) + '_lat'\n",
    "            lng = str(bsid) + '_lng'\n",
    "            df_feat.loc[idx, lat] = lats[r] * min_rssi\n",
    "            df_feat.loc[idx, lng] = lngs[r] * min_rssi\n",
    "        idx = idx + 1\n",
    "    return df_feat\n",
    "\n",
    "\n",
    "# METHOD 2\n",
    "def rssis(df, list_of_bs):\n",
    "    list_columns = [str(bs) + '_rssi' for bs in list_of_bs] + ['did']\n",
    "\n",
    "    df_mess_bs_group = df.groupby(['objid'], as_index=False)  # group data by message (objid)\n",
    "    messages = np.unique(df['objid'])\n",
    "    nb_mess = len(messages)\n",
    "\n",
    "    df_feat = pd.DataFrame(np.zeros((nb_mess, len(list_columns))), columns=list_columns)\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for key, elmt in df_mess_bs_group:\n",
    "        values = df_mess_bs_group.get_group(key)['rssi'].values\n",
    "        test = [v for v in values if v < -140]\n",
    "        if len(values) == len(test):\n",
    "            print(len(values), len(test))\n",
    "        df_feat.loc[idx, 'did'] = df_mess_bs_group.get_group(key)['did'].values[0]\n",
    "        for r, bsid in enumerate(df_mess_bs_group.get_group(key)['bsid'], 0):\n",
    "            rssi = str(bsid) + '_rssi'\n",
    "            df_feat.loc[idx, rssi] = values[r]\n",
    "        idx = idx + 1\n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rssis_filtered(df, list_of_bs):\n",
    "    list_columns = [str(bs) + '_rssi' for bs in list_of_bs] + ['did']\n",
    "\n",
    "    print('list_columnms', list_of_bs[:2], '...')\n",
    "    df_mess_bs_group = df.groupby(['objid'], as_index=False)  # group data by message (objid)\n",
    "    print(\"df_mess_bs_group\", df_mess_bs_group)\n",
    "    messages = np.unique(df['objid'])\n",
    "    print(\"messages\", messages[:2], '...')\n",
    "    nb_mess = len(messages)\n",
    "    print(\"nb_mess\", nb_mess)\n",
    "\n",
    "    df_feat = pd.DataFrame(np.zeros((nb_mess, len(list_columns))), columns=list_columns)\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for key, elmt in df_mess_bs_group:\n",
    "        values = df_mess_bs_group.get_group(key)['rssi'].values\n",
    "        test = [v for v in values if v < -140]\n",
    "        if len(values) == len(test):\n",
    "            print(len(values), len(test))\n",
    "        df_feat.loc[idx, 'did'] = df_mess_bs_group.get_group(key)['did'].values[0]\n",
    "        for r, bsid in enumerate(df_mess_bs_group.get_group(key)['bsid'], 0):\n",
    "            rssi = str(bsid) + '_rssi'\n",
    "            df_feat.loc[idx, rssi] = values[r]\n",
    "        idx = idx + 1\n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rssis_filtered(df, list_of_bs):\n",
    "    list_columns = [str(bs) + '_rssi' for bs in list_of_bs] + ['did']\n",
    "    df_mess_bs_group = df.groupby(['objid'], as_index=False)  # group data by message (objid)\n",
    "\n",
    "    nbObjid = len(set(df['objid'])) #number of messages\n",
    "    df_feat = pd.DataFrame(np.zeros((nbObjid, len(list_columns))), columns=list_columns)\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for objid, df_objid in df_mess_bs_group:    \n",
    "        objid_rssis = df_objid['rssi'].values\n",
    "        test = [r for r in objid_rssis if r < -140]\n",
    "\n",
    "        if len(objid_rssis) == len(test):\n",
    "            print(len(objid_rssis), len(test))\n",
    "            #TODO To the fucking job\n",
    "\n",
    "        df_feat.loc[idx, 'did'] = df_objid['did'].values[0]\n",
    "\n",
    "        for r, bsid in enumerate(df_objid['bsid'], 0):\n",
    "\n",
    "            col_name = str(bsid) + '_rssi'\n",
    "            df_feat.loc[idx, col_name] = objid_rssis[r]\n",
    "        idx = idx + 1\n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/home/bud/Documents/MyPrivateJoke/P2/INF730/data/\"\n",
    "files = [\"train_X.csv\", \"val_X.csv\", \"test_X.csv\", \"train_y.csv\", \"val_y.csv\", \"rssis_filtered\"]\n",
    "#    Available methods : lat_lng_dummies, rssi\n",
    "args = [path_data + file for file in files[:-1]]\n",
    "args.append(files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to DataFrames\n",
    "train = read_csv(args[0])\n",
    "val = read_csv(args[1])\n",
    "test = read_csv(args[2])\n",
    "\n",
    "y_train = read_csv(args[3])\n",
    "y_val = read_csv(args[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original lengths:\n",
      "\ttrain:\t 29805 \n",
      "\tval:\t 9445 \n",
      "\ttest:\t 29286\n",
      "\n",
      "Method applied: rssis_filtered\n",
      "list_columnms [879 911] ...\n",
      "df_mess_bs_group <pandas.core.groupby.DataFrameGroupBy object at 0x7f5c62321940>\n",
      "messages ['573bf1d9864fce1a9af8c5c9' '573bf3533e952e19126b256a'] ...\n",
      "nb_mess 5046\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "list_columnms [879 911] ...\n",
      "df_mess_bs_group <pandas.core.groupby.DataFrameGroupBy object at 0x7f5c622af400>\n",
      "messages ['582ae03712f1434b9cc93a71' '582ae1d712f1434b9ccad421'] ...\n",
      "nb_mess 1022\n",
      "1 1\n",
      "list_columnms [879 911] ...\n",
      "df_mess_bs_group <pandas.core.groupby.DataFrameGroupBy object at 0x7f5c62321ac8>\n",
      "messages ['573be2503e952e191262c351' '573c05f83e952e1912758013'] ...\n",
      "nb_mess 5294\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "# determine all Base stations that received at least 1 message\n",
    "list_of_bs = np.union1d(np.union1d(np.unique(train['bsid']), np.unique(val['bsid'])), np.unique(test['bsid']))\n",
    "\n",
    "means = compute_total_mean(train, val, test)\n",
    "min_rssi = compute_total_min(train, val, test)\n",
    "\n",
    "print(\"Original lengths:\\n\\ttrain:\\t\", len(train), \"\\n\\tval:\\t\", len(val), \"\\n\\ttest:\\t\", len(test))\n",
    "\n",
    "gt_train = ground_truth_const(train, y_train)\n",
    "gt_val = ground_truth_const(val, y_val)\n",
    "\n",
    "# save_csv(gt_train, 'ground_truth_train.csv')\n",
    "# save_csv(gt_val, 'ground_truth_val.csv')\n",
    "# print(\"Length ground truths : \", len(gt_train), len(gt_val))\n",
    "\n",
    "# get method\n",
    "method = args[5]\n",
    "print(\"\\nMethod applied:\", method)\n",
    "df_train = apply_method(method, train, means, min_rssi, list_of_bs)\n",
    "df_val = apply_method(method, val, means, min_rssi, list_of_bs)\n",
    "df_test = apply_method(method, test, means, min_rssi, list_of_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = [str(bs) + '_rssi' for bs in list_of_bs] + ['did']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting done.\n",
      "New lengths :  5046 1022 5294\n",
      "\t| Columns length\n",
      "\t|  260 260 260\n"
     ]
    }
   ],
   "source": [
    "print(\"Formatting done.\\nNew lengths : \", len(df_train), len(df_val), len(df_test))\n",
    "\n",
    "print(\"\\t| Columns length\")\n",
    "print(\"\\t| \", len(df_train.columns.values), len(df_val.columns.values), len(df_test.columns.values))\n",
    "\n",
    "# save\n",
    "save_csv(df_train, path_data+'train_formatted_' + method + '.csv')\n",
    "save_csv(df_val, path_data+'val_formatted_' + method + '.csv')\n",
    "save_csv(df_test, path_data+'test_formatted_' + method + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
